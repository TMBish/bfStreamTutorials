{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "import tarfile\n",
    "import zipfile\n",
    "import bz2\n",
    "import glob\n",
    "import logging\n",
    "import yaml\n",
    "\n",
    "from datetime import date, timedelta\n",
    "from unittest.mock import patch\n",
    "from typing import List, Set, Dict, Tuple, Optional\n",
    "from itertools import zip_longest\n",
    "import betfairlightweight\n",
    "from betfairlightweight import StreamListener\n",
    "from betfairlightweight.resources.bettingresources import (\n",
    "    PriceSize,\n",
    "    MarketBook\n",
    ")\n",
    "\n",
    "# Utility Functions\n",
    "# _________________________________\n",
    "\n",
    "def as_str(v) -> str:\n",
    "    return '%.2f' % v if type(v) is float else v if type(v) is str else ''\n",
    "\n",
    "def split_anz_horse_market_name(market_name: str) -> (str, str, str):\n",
    "    parts = market_name.split(' ')\n",
    "    race_no = parts[0] # return example R6\n",
    "    race_len = parts[1] # return example 1400m\n",
    "    race_type = parts[2].lower() # return example grp1, trot, pace\n",
    "    return (race_no, race_len, race_type)\n",
    "\n",
    "\n",
    "def load_markets(file_paths):\n",
    "    for file_path in file_paths:\n",
    "        print(file_path)\n",
    "        if os.path.isdir(file_path):\n",
    "            for path in glob.iglob(file_path + '**/**/*.bz2', recursive=True):\n",
    "                f = bz2.BZ2File(path, 'rb')\n",
    "                yield f\n",
    "                f.close()\n",
    "        elif os.path.isfile(file_path):\n",
    "            ext = os.path.splitext(file_path)[1]\n",
    "            # iterate through a tar archive\n",
    "            if ext == '.tar':\n",
    "                with tarfile.TarFile(file_path) as archive:\n",
    "                    for file in archive:\n",
    "                        yield bz2.open(archive.extractfile(file))\n",
    "            # or a zip archive\n",
    "            elif ext == '.zip':\n",
    "                with zipfile.ZipFile(file_path) as archive:\n",
    "                    for file in archive.namelist():\n",
    "                        yield bz2.open(archive.open(file))\n",
    "\n",
    "    return None\n",
    "\n",
    "def slicePrice(l, n):\n",
    "    try:\n",
    "        x = l[n].price\n",
    "    except:\n",
    "        x = \"\"\n",
    "    return(x)\n",
    "\n",
    "def sliceSize(l, n):\n",
    "    try:\n",
    "        x = l[n].size\n",
    "    except:\n",
    "        x = \"\"\n",
    "    return(x)\n",
    "\n",
    "def pull_ladder(availableLadder, n = 5):\n",
    "        out = {}\n",
    "        price = []\n",
    "        volume = []\n",
    "        if len(availableLadder) == 0:\n",
    "            return(out)        \n",
    "        else:\n",
    "            for rung in availableLadder[0:n]:\n",
    "                price.append(rung.price)\n",
    "                volume.append(rung.size)\n",
    "\n",
    "            out[\"p\"] = price\n",
    "            out[\"v\"] = volume\n",
    "            return(out)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "with open(\"../../secrets.yaml\", 'r') as stream:\n",
    "    creds = yaml.safe_load(stream)\n",
    "\n",
    "trading = betfairlightweight.APIClient(creds['uid'], creds['pwd'],  app_key=creds[\"api_key\"])\n",
    "\n",
    "listener = StreamListener(max_latency=None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extraction Notes\n",
    "\n",
    "\n",
    "## Scope\n",
    "\n",
    "- We want to extract predominantly preplay price data\n",
    "- We also want to extract multiple price points per runner\n",
    "- We also want final results and BSPs\n",
    "- We probably want the time granularities to be split into chunks (start at 30 mins before off, every minute until 10 mins, then every second until off)\n",
    "- The market components we want to extract I can think of rn are:\n",
    "    + Probably take the whole available to back ladder, available to lay ladder, and traded volume ladder up to a certain amount\n",
    "\n",
    "## Conclusion\n",
    "So we might want to filter for a few tracks because this is going to be a lot of data. Maybe filter on big Victorian tracks or something.\n",
    "Also might want to split the extraction into 2 components: preplay, and runner summary so I can keep the below code pattern that I coded up for the angles piece initially.\n",
    "\n",
    "In a seperate script I figured out the top 5 tracks by volume per market are: Flemington, Caulfield, Moonee Valley, Bendigo, Sandown. Need to be careful about the venue names in the stream files which are going to be invariably different."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def filter_market(market: MarketBook) -> bool: \n",
    "    \n",
    "    d = market.market_definition\n",
    "    track_filter = ['Bendigo', 'Sandown', 'Flemington', 'Caulfield', 'Moonee Valley']\n",
    "\n",
    "    return (d.country_code == 'AU' \n",
    "        and d.venue in track_filter\n",
    "        and d.market_type == 'WIN' \n",
    "        and (c := split_anz_horse_market_name(d.name)[2]) != 'trot' and c != 'pace')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preplay Prices"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "log1_Start = 60 * 30 # Seconds before scheduled off to start recording data for data segment one\n",
    "log1_Step = 60       # Seconds between log steps for first data segment\n",
    "log2_Start = 60 * 10  # Seconds before scheduled off to start recording data for data segment two\n",
    "log2_Step = 1        # Seconds between log steps for second data segment\n",
    "\n",
    "def loop_preplay_prices(s, o):\n",
    "\n",
    "    with patch(\"builtins.open\", lambda f, _: f):\n",
    "\n",
    "        gen = s.get_generator()\n",
    "\n",
    "        marketID = None\n",
    "        tradeVols = None\n",
    "        time = None\n",
    "\n",
    "        for market_books in gen():\n",
    "\n",
    "            # Check if this market book meets our market filter\n",
    "            # ________________________________\n",
    "\n",
    "            if ((evaluate_market := filter_market(market_books[0])) == False):\n",
    "                    break\n",
    "\n",
    "            for market_book in market_books:\n",
    "\n",
    "                # Time Step Management\n",
    "                # _____________________\n",
    "\n",
    "                if marketID is None:\n",
    "\n",
    "                    # No market initialised\n",
    "                    marketID = market_book.market_id\n",
    "                    time =  market_book.publish_time\n",
    "\n",
    "                elif market_book.inplay:\n",
    "\n",
    "                    # Stop once market goes inplay\n",
    "                    break\n",
    "\n",
    "                else:\n",
    "                    \n",
    "                    seconds_to_start = (market_book.market_definition.market_time - market_book.publish_time).total_seconds()\n",
    "\n",
    "                    if seconds_to_start <= log1_Start:\n",
    "                        \n",
    "                        # Too early before off to start logging prices\n",
    "                        continue\n",
    "\n",
    "                    else:\n",
    "                    \n",
    "                        # Update data at different time steps depending on seconds to off\n",
    "                        wait = np.where(seconds_to_start <= log2_Start, log2_Step, log1_Step)\n",
    "\n",
    "                        # New Market\n",
    "                        if market_book.market_id != marketID:\n",
    "                            marketID = market_book.market_id\n",
    "                            time =  market_book.publish_time\n",
    "                        # (wait) seconds elapsed since last write\n",
    "                        elif (market_book.publish_time - time).total_seconds() > wait:\n",
    "                            time = market_book.publish_time\n",
    "                        # fewer than (wait) seconds elapsed continue to next loop\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                # Execute Data Logging\n",
    "                # _____________________\n",
    "                                                \n",
    "                for runner in market_book.runners:\n",
    "\n",
    "                    try:\n",
    "                        atb_ladder = pull_ladder(runner.ex.available_to_back, n = 10)\n",
    "                        atl_ladder = pull_ladder(runner.ex.available_to_lay, n = 10)\n",
    "                    except:\n",
    "                        atb_ladder = {}\n",
    "                        atl_ladder = {}\n",
    "\n",
    "                    # Calculate Current Traded Volume + Tradedd WAP\n",
    "                    limitTradedVol = sum([rung.size for rung in runner.ex.traded_volume])\n",
    "                    if limitTradedVol == 0:\n",
    "                        limitWAP = \"\"\n",
    "                    else:\n",
    "                        limitWAP = sum([rung.size * rung.price for rung in runner.ex.traded_volume]) / limitTradedVol\n",
    "                        limitWAP = round(limitWAP, 2)\n",
    "\n",
    "                    o.write(\n",
    "                        \"{}, {}, {}, {}, {}, {}, {}, {}\\n\".format(\n",
    "                            market_book.market_id,\n",
    "                            runner.selection_id,\n",
    "                            market_book.publish_time,\n",
    "                            limitTradedVol,\n",
    "                            limitWAP,\n",
    "                            runner.last_price_traded or \"\",\n",
    "                            '\"' + str(atb_ladder).replace(' ','') + '\"', \n",
    "                            '\"' + str(atl_ladder).replace(' ','') + '\"'\n",
    "                        )\n",
    "                    )   \n",
    "\n",
    "def parse_preplay_prices(dir, out_file):\n",
    "    \n",
    "    with open(output_file, \"w+\") as output:\n",
    "\n",
    "        output.write(\"market_id,selection_id,time,traded_volume,wap,ltp,atb_ladder,atl_ladder\\n\")\n",
    "\n",
    "        for file_obj in load_markets(dir):\n",
    "\n",
    "            stream = trading.streaming.create_historical_generator_stream(\n",
    "                file_path=file_obj,\n",
    "                listener=listener,\n",
    "            )\n",
    "\n",
    "            loop_preplay_prices(stream, output)\n",
    "\n",
    "\n",
    "output_file = \"/media/hdd/tmp/thoroughbred-parsed/vic-tho-preplay-price-movements.csv\"\n",
    "\n",
    "#parse_preplay_prices([\"/media/hdd/data/betfair-stream/thoroughbred/2021_06_JunRacingAUPro.tar\"], output_file)"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Market Meta"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def final_market_book(s):\n",
    "\n",
    "    with patch(\"builtins.open\", lambda f, _: f):\n",
    "\n",
    "        gen = s.get_generator()\n",
    "\n",
    "        for market_books in gen():\n",
    "            \n",
    "            # Check if this market book meets our market filter\n",
    "            # ________________________________\n",
    "\n",
    "            if ((evaluate_market := filter_market(market_books[0])) == False):\n",
    "                    return(None)\n",
    "            \n",
    "            for market_book in market_books:\n",
    "\n",
    "                last_market_book = market_book\n",
    "        \n",
    "        return(last_market_book)\n",
    "\n",
    "\n",
    "def parse_final_selection_meta(dir):\n",
    "    \n",
    "    # with open(output_file, \"w+\") as output:\n",
    "\n",
    "        #output.write(\"market_id,selection_id,time,traded_volume,wap,ltp,atb_ladder,atl_ladder\\n\")\n",
    "\n",
    "    for file_obj in load_markets(dir):\n",
    "\n",
    "        stream = trading.streaming.create_historical_generator_stream(\n",
    "            file_path=file_obj,\n",
    "            listener=listener,\n",
    "        )\n",
    "\n",
    "        last_market_book = final_market_book(stream)\n",
    "\n",
    "        if last_market_book is None:\n",
    "            continue \n",
    "\n",
    "        # Extract Info\n",
    "        # _____________________________________\n",
    "\n",
    "        runnerMeta = [\n",
    "            {\n",
    "                'selection_id': r.selection_id,\n",
    "                'selection_name': next((rd.name for rd in last_market_book.market_definition.runners if rd.selection_id == r.selection_id), None),\n",
    "                'selection_status': r.status,\n",
    "                'win': np.where(r.status == \"WINNER\", 1, 0),\n",
    "                'sp': r.sp.actual_sp\n",
    "            }\n",
    "            for r in last_market_book.runners \n",
    "        ]\n",
    "\n",
    "        # Return Info\n",
    "        # _____________________________________\n",
    "\n",
    "        for runnerMeta in runnerMeta:\n",
    "\n",
    "            if runnerMeta['selection_status'] != 'REMOVED':\n",
    "\n",
    "                print(\n",
    "                    \"{},{},{},{},{},{},{}\\n\".format(\n",
    "                        str(last_market_book.market_id),\n",
    "                        last_market_book.market_definition.venue,\n",
    "                        last_market_book.market_definition.market_time,\n",
    "                        runnerMeta['selection_id'],\n",
    "                        runnerMeta['selection_name'],\n",
    "                        runnerMeta['win'],\n",
    "                        runnerMeta['sp']\n",
    "                    )\n",
    "                )\n",
    "\n",
    "parse_final_selection_meta([\"/media/hdd/data/betfair-stream/thoroughbred/2021_06_JunRacingAUPro.tar\"])\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/media/hdd/data/betfair-stream/thoroughbred/2021_06_JunRacingAUPro.tar\n",
      "1.184024305,Sandown,2021-06-02 02:25:00,39648870,1. Diamond Dagger,0,12.27\n",
      "\n",
      "1.184024305,Sandown,2021-06-02 02:25:00,39648871,3. Finch N Chips,0,13.5\n",
      "\n",
      "1.184024305,Sandown,2021-06-02 02:25:00,39648873,5. Nuriya,0,86.05\n",
      "\n",
      "1.184024305,Sandown,2021-06-02 02:25:00,39308845,6. Oceans Jen,1,7.8\n",
      "\n",
      "1.184024305,Sandown,2021-06-02 02:25:00,39509292,7. Red Sista,0,8.3\n",
      "\n",
      "1.184024305,Sandown,2021-06-02 02:25:00,39648874,8. Surangani,0,69.79\n",
      "\n",
      "1.184024305,Sandown,2021-06-02 02:25:00,31554076,9. Write The Score,0,2.19\n",
      "\n",
      "1.184024305,Sandown,2021-06-02 02:25:00,39089152,10. Wyld Savanna,0,8.38\n",
      "\n",
      "1.184024307,Sandown,2021-06-02 03:00:00,39648875,1. Aktolgali,0,188.85\n",
      "\n",
      "1.184024307,Sandown,2021-06-02 03:00:00,39648876,2. Jungle Magnate,1,10.95\n",
      "\n",
      "1.184024307,Sandown,2021-06-02 03:00:00,2241826,3. Royal Fox,0,3.45\n",
      "\n",
      "1.184024307,Sandown,2021-06-02 03:00:00,39648877,4. Arohaboy,0,41.29\n",
      "\n",
      "1.184024307,Sandown,2021-06-02 03:00:00,8949957,5. Back In The Day,0,10.54\n",
      "\n",
      "1.184024307,Sandown,2021-06-02 03:00:00,2934316,6. Eidolon,0,18.0\n",
      "\n",
      "1.184024307,Sandown,2021-06-02 03:00:00,39648878,8. Mac N Cheese,0,2.62\n",
      "\n",
      "1.184024307,Sandown,2021-06-02 03:00:00,39648879,9. Miss November,0,27.21\n",
      "\n",
      "1.184024307,Sandown,2021-06-02 03:00:00,39648880,10. Vancity,0,46.0\n",
      "\n",
      "1.184024309,Sandown,2021-06-02 03:35:00,39648881,1. Montia,0,9.8\n",
      "\n",
      "1.184024309,Sandown,2021-06-02 03:35:00,39648882,2. Spooning,0,2.89\n",
      "\n",
      "1.184024309,Sandown,2021-06-02 03:35:00,9377150,3. Star Of Eden,1,7.8\n",
      "\n",
      "1.184024309,Sandown,2021-06-02 03:35:00,39648886,7. Miss Tainui,0,11.6\n",
      "\n",
      "1.184024309,Sandown,2021-06-02 03:35:00,39648887,8. Seduce,0,17.06\n",
      "\n",
      "1.184024309,Sandown,2021-06-02 03:35:00,36772101,9. Countess Tessa,0,19.15\n",
      "\n",
      "1.184024309,Sandown,2021-06-02 03:35:00,35635071,10. Laudeylou,0,7.37\n",
      "\n",
      "1.184024309,Sandown,2021-06-02 03:35:00,38597694,11. Promada,0,11.01\n",
      "\n",
      "1.184024309,Sandown,2021-06-02 03:35:00,39133421,12. Shilajit,0,145.93\n",
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_222590/2299223283.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 )\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0mparse_final_selection_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"/media/hdd/data/betfair-stream/thoroughbred/2021_06_JunRacingAUPro.tar\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_222590/2299223283.py\u001b[0m in \u001b[0;36mparse_final_selection_meta\u001b[0;34m(dir)\u001b[0m\n\u001b[1;32m     33\u001b[0m         )\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mlast_market_book\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_market_book\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlast_market_book\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_222590/2299223283.py\u001b[0m in \u001b[0;36mfinal_market_book\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmarket_books\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;31m# Check if this market book meets our market filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/betfairlightweight/streaming/betfairstream.py\u001b[0m in \u001b[0;36m_read_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m                     \u001b[0;31m# if on_data returns an error stop the stream and raise error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/betfairlightweight/streaming/listener.py\u001b[0m in \u001b[0;36mon_data\u001b[0;34m(self, raw_data)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 )\n\u001b[1;32m    143\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_change_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_on_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/betfairlightweight/streaming/listener.py\u001b[0m in \u001b[0;36m_on_change_message\u001b[0;34m(self, data, unique_id)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             logger.debug(  # very slow call due to data dict\n\u001b[0;32m--> 177\u001b[0;31m                 \u001b[0;34m\"[%s: %s]: %s: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchange_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m             )\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  }
 ]
}