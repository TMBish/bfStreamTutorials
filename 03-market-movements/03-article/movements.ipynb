{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Do #theyknow? Analysing betfair market formation and market movements"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 0.1 Setup\n",
                "\n",
                "Once again I'll be presenting the analysis in a jupyter notebook and will be using python as a programming language.\n",
                "\n",
                "Some of the data processing code takes a while to execute - that code will be in cells that are commented out - and will require a bit of adjustment to point to places on your computer locally where you want to store the intermediate data files.\n",
                "\n",
                "You'll also need `betfairlightweight` which you can install with something like `pip install betfairlightweight`."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import requests\n",
                "import os\n",
                "import re\n",
                "import csv\n",
                "import plotly.express as px\n",
                "import plotly.graph_objects as go\n",
                "import math\n",
                "import logging\n",
                "import yaml\n",
                "import csv\n",
                "import tarfile\n",
                "import zipfile\n",
                "import bz2\n",
                "import glob\n",
                "\n",
                "from datetime import date, timedelta\n",
                "from unittest.mock import patch\n",
                "from typing import List, Set, Dict, Tuple, Optional\n",
                "from itertools import zip_longest\n",
                "import betfairlightweight\n",
                "from betfairlightweight import StreamListener\n",
                "from betfairlightweight.resources.bettingresources import (\n",
                "    PriceSize,\n",
                "    MarketBook\n",
                ")"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 0.2 Context\n",
                "\n",
                "You may have seen the hashtag if you're on australian racing twitter #theyknow following a dramatic late market move for a horse that's followed by a decisive race victory. Sometimes it can seem eerie how accurate these moves are after the fact. In betfair racing markets there's usually a flurry of activity leading up to the race start as players look to get their bets down at the best price without tipping their hand (opinion on the race) too much. Large moves can happend when large players rally around a selection who's implied chance in early trading isn't close to what it's true chance is in the upcoming race. Large moves can also happen when there's some inside information - not able to be gleaned from analysis of the horses previous races - that slowly filters out of the stable or training group.\n",
                "\n",
                "This creates opportunity in the secondary market as punters try to read these movements to make bets themselves. The task often becomes identifying which movements are caused by these sophisticated players or represent real signals of strength and which aren't.\n",
                "\n",
                "So do #theyknow generally? Before even looking at the data I can assure you that yes they do know pretty well. Strong movements in betting markets are usually pretty reliable indicators about what is about to happen. However, these moves can be overvalued. Observing a horse plumet in from $3.50 to $2 you are usually suprised if the horse loses, but the general efficiency of late prices would suggest that this horse is going to still lose 50% of time. On the other hand what if would could reliably identify the move as it was happening or about to happen? That would be a recipe for successful trading of horse racing markets and no doubt this is what many players in this secondary market (analysis of betfair markets rather than the races themselves) try to do.\n",
                "\n",
                "If you were to build up a manual qualitative strategy for this kind of market trading you need to understand:\n",
                "- Who the participants are\n",
                "- How sophisticated they are at the top end\n",
                "- What types of races do they bet on and for how much\n",
                "- When the different types of participants typically enter the market \n",
                "- What do bet placement patterns look like for these participants\n",
                "- etc.\n",
                "\n",
                "This is the kind of task that takes a lot research, a lot of trial and error, and a lot of industry know-how. Given I'm a lazy quantitative person I'll try to see if I can uncover any of these patterns in the data alone."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 0.3 This Example\n",
                "\n",
                "Building market based trading strategies is a broad and fertile ground for many quantitative betfair customers; too big to cover in a single article. I'll try to zero in on a small slice of thoroughbred markets and analyse how these markets form and how I'd start the process of trying to find the patterns in the market movements. Again hopefully this is some inspiration for you and you can pick up some of the ideas and build them out.\n",
                "\n",
                "Given volume of data (when analysing second by second slices of market data) I'll be looking at a years worth of thoroughbred races from the 5 largest Victorian tracks: Flemington, Caulfield, Moonee Valley, Bendigo and Sandown."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# 1.0 Data\n",
                "\n",
                "Unlike in some of the previous tutorials we aren't going to collapse the stream data into a single row per runner. In those examples we were interested in analysing some discrete things about selections in betfair markets like:\n",
                "\n",
                "- Their final odds (bsp or last traded price)\n",
                "- Their odds at some fixed time point or time points before the scheduled race start\n",
                "- Other single number descriptors of the trading activity on a selection (eg total traded volume)\n",
                "\n",
                "\n",
                "In this analysis I want to analyse how markets form and prices move for selections as markets evolve. So we'll need to pull out multiple price points per runner - so we'll have multiple output rows per runner in our parsed dataset.\n",
                "\n",
                "To output a row for every stream update for every selection in every thoroughbred race over the last 12 months would produce a dataset far too big too analyse using normal data analysis tools - we're talking about billions of rows.\n",
                "\n",
                "To chop our sample down into a manageable slice I'm going to filter on some select tracks of interest (as mentioned above) and I'm also going to have 3 sections of data granularity:\n",
                "\n",
                "- I won't log any of the odds or traded volumes > 30mins before the scheduled off\n",
                "    + In thoroughbreds there is non-trivial action before this point you may want to study, but it's not what I want to study here\n",
                "- Between 30 and 10 minutes before the scheduled off I'll log data every 60 seconds\n",
                "- 10 minutes or less to the scheuled off I'll log prices every second\n",
                "\n",
                "The code to manage this windowed granularity is in the below parsing code tweak as you wish if you want to tighten or broaden the analysis.\n",
                "\n"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 1.1 Utility Functions"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "# General Utility Functions\n",
                "# _________________________________\n",
                "\n",
                "def as_str(v) -> str:\n",
                "    return '%.2f' % v if type(v) is float else v if type(v) is str else ''\n",
                "\n",
                "def split_anz_horse_market_name(market_name: str) -> (str, str, str):\n",
                "    parts = market_name.split(' ')\n",
                "    race_no = parts[0] # return example R6\n",
                "    race_len = parts[1] # return example 1400m\n",
                "    race_type = parts[2].lower() # return example grp1, trot, pace\n",
                "    return (race_no, race_len, race_type)\n",
                "\n",
                "\n",
                "def load_markets(file_paths):\n",
                "    for file_path in file_paths:\n",
                "        print(file_path)\n",
                "        if os.path.isdir(file_path):\n",
                "            for path in glob.iglob(file_path + '**/**/*.bz2', recursive=True):\n",
                "                f = bz2.BZ2File(path, 'rb')\n",
                "                yield f\n",
                "                f.close()\n",
                "        elif os.path.isfile(file_path):\n",
                "            ext = os.path.splitext(file_path)[1]\n",
                "            # iterate through a tar archive\n",
                "            if ext == '.tar':\n",
                "                with tarfile.TarFile(file_path) as archive:\n",
                "                    for file in archive:\n",
                "                        yield bz2.open(archive.extractfile(file))\n",
                "            # or a zip archive\n",
                "            elif ext == '.zip':\n",
                "                with zipfile.ZipFile(file_path) as archive:\n",
                "                    for file in archive.namelist():\n",
                "                        yield bz2.open(archive.open(file))\n",
                "\n",
                "    return None\n",
                "\n",
                "def slicePrice(l, n):\n",
                "    try:\n",
                "        x = l[n].price\n",
                "    except:\n",
                "        x = \"\"\n",
                "    return(x)\n",
                "\n",
                "def sliceSize(l, n):\n",
                "    try:\n",
                "        x = l[n].size\n",
                "    except:\n",
                "        x = \"\"\n",
                "    return(x)\n",
                "\n",
                "def pull_ladder(availableLadder, n = 5):\n",
                "        out = {}\n",
                "        price = []\n",
                "        volume = []\n",
                "        if len(availableLadder) == 0:\n",
                "            return(out)        \n",
                "        else:\n",
                "            for rung in availableLadder[0:n]:\n",
                "                price.append(rung.price)\n",
                "                volume.append(rung.size)\n",
                "\n",
                "            out[\"p\"] = price\n",
                "            out[\"v\"] = volume\n",
                "            return(out)\n",
                "\n",
                "trading = betfairlightweight.APIClient(\"username\", \"password\")\n",
                "listener = StreamListener(max_latency=None)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Slicing the tracks we want we'll just adjust the market filter function used before to include some logic on the venue name"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "def filter_market(market: MarketBook) -> bool: \n",
                "    \n",
                "    d = market.market_definition\n",
                "    track_filter = ['Bendigo', 'Sandown', 'Flemington', 'Caulfield', 'Moonee Valley']\n",
                "\n",
                "    return (d.country_code == 'AU' \n",
                "        and d.venue in track_filter\n",
                "        and d.market_type == 'WIN' \n",
                "        and (c := split_anz_horse_market_name(d.name)[2]) != 'trot' and c != 'pace')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 1.3 Selection Metadata\n",
                "\n",
                "Given that the detailed price data will have so many records we will split out the selection metadata (including the selection win outcome flag and the bsp) into it's own dataset much you would do in a relational database to manage data volumes.\n",
                "\n",
                "This means we'll have to parse over the data twice but our outputs will be much smaller than if we duplicated the selection name 800 times for example."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "def final_market_book(s):\n",
                "\n",
                "    with patch(\"builtins.open\", lambda f, _: f):\n",
                "\n",
                "        gen = s.get_generator()\n",
                "\n",
                "        for market_books in gen():\n",
                "            \n",
                "            # Check if this market book meets our market filter ++++++++++++++++++++++++++++++++++\n",
                "\n",
                "            if ((evaluate_market := filter_market(market_books[0])) == False):\n",
                "                    return(None)\n",
                "            \n",
                "            for market_book in market_books:\n",
                "\n",
                "                last_market_book = market_book\n",
                "        \n",
                "        return(last_market_book)\n",
                "\n",
                "def parse_final_selection_meta(dir, out_file):\n",
                "    \n",
                "    with open(out_file, \"w+\") as output:\n",
                "\n",
                "        output.write(\"market_id,selection_id,venue,market_time,selection_name,win,bsp\\n\")\n",
                "\n",
                "        for file_obj in load_markets(dir):\n",
                "\n",
                "            stream = trading.streaming.create_historical_generator_stream(\n",
                "                file_path=file_obj,\n",
                "                listener=listener,\n",
                "            )\n",
                "\n",
                "            last_market_book = final_market_book(stream)\n",
                "\n",
                "            if last_market_book is None:\n",
                "                continue \n",
                "\n",
                "            # Extract Info ++++++++++++++++++++++++++++++++++\n",
                "\n",
                "            runnerMeta = [\n",
                "                {\n",
                "                    'selection_id': r.selection_id,\n",
                "                    'selection_name': next((rd.name for rd in last_market_book.market_definition.runners if rd.selection_id == r.selection_id), None),\n",
                "                    'selection_status': r.status,\n",
                "                    'win': np.where(r.status == \"WINNER\", 1, 0),\n",
                "                    'sp': r.sp.actual_sp\n",
                "                }\n",
                "                for r in last_market_book.runners \n",
                "            ]\n",
                "\n",
                "            # Return Info ++++++++++++++++++++++++++++++++++\n",
                "\n",
                "            for runnerMeta in runnerMeta:\n",
                "\n",
                "                if runnerMeta['selection_status'] != 'REMOVED':\n",
                "\n",
                "                    output.write(\n",
                "                        \"{},{},{},{},{},{},{}\\n\".format(\n",
                "                            str(last_market_book.market_id),\n",
                "                            runnerMeta['selection_id'],\n",
                "                            last_market_book.market_definition.venue,\n",
                "                            last_market_book.market_definition.market_time,\n",
                "                            runnerMeta['selection_name'],\n",
                "                            runnerMeta['win'],\n",
                "                            runnerMeta['sp']\n",
                "                        )\n",
                "                    )"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "selection_meta = \"[OUTPUT PATH TO CSV FOR SELECTION METADATA]\"\n",
                "stream_files = glob.glob(\"[PATH TO STREAM FILES]*.tar\")\n",
                "\n",
                "print(\"__ Parsing Selection Metadata ___ \")\n",
                "# parse_final_selection_meta(stream_files, selection_meta)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 1.3 Detailed Preplay Odds\n",
                "\n",
                "Like mentioned above there will be some time control logic injected to control time granularity in each step.\n"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def loop_preplay_prices(s, o):\n",
                "\n",
                "    with patch(\"builtins.open\", lambda f, _: f):\n",
                "\n",
                "        gen = s.get_generator()\n",
                "\n",
                "        marketID = None\n",
                "        tradeVols = None\n",
                "        time = None\n",
                "\n",
                "        for market_books in gen():\n",
                "\n",
                "            # Check if this market book meets our market filter ++++++++++++++++++++++++++++++++++\n",
                "\n",
                "            if ((evaluate_market := filter_market(market_books[0])) == False):\n",
                "                    break\n",
                "\n",
                "            for market_book in market_books:\n",
                "\n",
                "                # Time Step Management ++++++++++++++++++++++++++++++++++\n",
                "\n",
                "                if marketID is None:\n",
                "\n",
                "                    # No market initialised\n",
                "                    marketID = market_book.market_id\n",
                "                    time =  market_book.publish_time\n",
                "\n",
                "                elif market_book.inplay:\n",
                "\n",
                "                    # Stop once market goes inplay\n",
                "                    break\n",
                "\n",
                "                else:\n",
                "                    \n",
                "                    seconds_to_start = (market_book.market_definition.market_time - market_book.publish_time).total_seconds()\n",
                "\n",
                "                    if seconds_to_start > log1_Start:\n",
                "                        \n",
                "                        # Too early before off to start logging prices\n",
                "                        continue\n",
                "\n",
                "                    else:\n",
                "                    \n",
                "                        # Update data at different time steps depending on seconds to off\n",
                "                        wait = np.where(seconds_to_start <= log2_Start, log2_Step, log1_Step)\n",
                "\n",
                "                        # New Market\n",
                "                        if market_book.market_id != marketID:\n",
                "                            marketID = market_book.market_id\n",
                "                            time =  market_book.publish_time\n",
                "                        # (wait) seconds elapsed since last write\n",
                "                        elif (market_book.publish_time - time).total_seconds() > wait:\n",
                "                            time = market_book.publish_time\n",
                "                        # fewer than (wait) seconds elapsed continue to next loop\n",
                "                        else:\n",
                "                            continue\n",
                "\n",
                "                # Execute Data Logging ++++++++++++++++++++++++++++++++++\n",
                "                                                \n",
                "                for runner in market_book.runners:\n",
                "\n",
                "                    try:\n",
                "                        atb_ladder = pull_ladder(runner.ex.available_to_back, n = 10)\n",
                "                        atl_ladder = pull_ladder(runner.ex.available_to_lay, n = 10)\n",
                "                    except:\n",
                "                        atb_ladder = {}\n",
                "                        atl_ladder = {}\n",
                "\n",
                "                    # Calculate Current Traded Volume + Tradedd WAP\n",
                "                    limitTradedVol = sum([rung.size for rung in runner.ex.traded_volume])\n",
                "                    if limitTradedVol == 0:\n",
                "                        limitWAP = \"\"\n",
                "                    else:\n",
                "                        limitWAP = sum([rung.size * rung.price for rung in runner.ex.traded_volume]) / limitTradedVol\n",
                "                        limitWAP = round(limitWAP, 2)\n",
                "\n",
                "                    o.writerow(\n",
                "                        (\n",
                "                            market_book.market_id,\n",
                "                            runner.selection_id,\n",
                "                            market_book.publish_time,\n",
                "                            limitTradedVol,\n",
                "                            limitWAP,\n",
                "                            runner.last_price_traded or \"\",\n",
                "                            str(atb_ladder).replace(' ',''), \n",
                "                            str(atl_ladder).replace(' ','')\n",
                "                        )\n",
                "                    )\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "def parse_preplay_prices(dir, out_file):\n",
                "    \n",
                "    with open(out_file, \"w+\") as output:\n",
                "\n",
                "        writer = csv.writer(\n",
                "            output, \n",
                "            delimiter=',',\n",
                "            lineterminator='\\r\\n',\n",
                "            quoting=csv.QUOTE_ALL\n",
                "        )\n",
                "        \n",
                "        writer.writerow((\"market_id\",\"selection_id\",\"time\",\"traded_volume\",\"wap\",\"ltp\",\"atb_ladder\",\"atl_ladder\"))\n",
                "\n",
                "        for file_obj in load_markets(dir):\n",
                "\n",
                "            stream = trading.streaming.create_historical_generator_stream(\n",
                "                file_path=file_obj,\n",
                "                listener=listener,\n",
                "            )\n",
                "\n",
                "            loop_preplay_prices(stream, writer)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "preplay_price_file =  \"[OUTPUT PATH TO CSV FOR PREPLAY PRICES]\"\n",
                "stream_files = glob.glob(\"[PATH TO STREAM FILES]*.tar\")\n",
                "\n",
                "\n",
                "log1_Start = 60 * 30 # Seconds before scheduled off to start recording data for data segment one\n",
                "log1_Step = 60       # Seconds between log steps for first data segment\n",
                "log2_Start = 60 * 10  # Seconds before scheduled off to start recording data for data segment two\n",
                "log2_Step = 1        # Seconds between log steps for second data segment\n",
                "\n",
                "print(\"__ Parsing Detailed Preplay Prices ___ \")\n",
                "# parse_preplay_prices(stream_files, preplay_price_file)"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.5",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.5 64-bit"
        },
        "interpreter": {
            "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}