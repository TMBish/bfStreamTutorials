{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtesting With Historical Stream Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context\n",
    "\n",
    "Backtesting is the life-blood of most succesful wagering systems. In short it attempts to answer a single question for you:\n",
    "\n",
    "> $ \\tau $ : How much money will I win or lose if I started using this system to place bets with real money? \n",
    "\n",
    "Without a rigorous and quantitative backtesting approach it's really quite hard to estimate the answer to this question $ \\tau $ that will be even reliably on the right side of zero. \n",
    "\n",
    "You could live test your system with real bets at small stakes, however, this isn't the panacea it seems. It will take time (more than you think) for your results to converge to their long term expectation. How long? Answering this question will require some expertise with probability and statistics you might not have. Even more than that though is that depending on where you're betting your results at small stakes could be very different than at larger stakes. You might not be able get a good answer to $ \\tau $ until betting at full stakes at which point finding the answer might coincide with blowing up your gambling bankroll.\n",
    "\n",
    "Backtesting is also very hard. To perfectly backtest your own predicted probablility on a historical race or sporting match you need to produce 2 things:\n",
    "\n",
    "> (1) What would my predicted chance have been **exactly** for this selection in this market on this day in the past?\n",
    "\n",
    "> (2) What would have I decided to bet **at what odds (exactly)** and **for how much stake (exactly)** based on this prediction? \n",
    "\n",
    "> ** where the devil tends to be in those **exactly**s.\n",
    "\n",
    "The aim of the backtesting game is answering (2) as accurately as possible because it tells you exactly how much you would have made over your backtesting period, from there you can confidently project that rate of profitability forward. \n",
    "\n",
    "It's easy to make mistakes and small errors in the quantitative reasoning can lead you to extremely misguided projections downstream. \n",
    "\n",
    "Question (1) won't be in the scope of this notebook but it's equally (and probably more) important thant (2) but it is the key challenge of all predictive modelling exercises so there's plenty of discussion about it elsewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtesting on Betfair\n",
    "\n",
    "Answering quistion (2) for betting on the betfair exchange is difficult. The exhange is a dynamic system that changes from one micro second to the next.\n",
    "\n",
    "> What number should you use for odds? How much could you assume to get down at those odds?\n",
    "\n",
    "The conventional and easiest approach is to backtest at the BSP. The BSP is simple because it's a single number (to use for both back and lay bets) and is a taken price (there's no uncertainty about getting matched). Depending on the liquidity of the market a resonably sized stake might also not move the BSP very much. For some markets you may be able to safely assume you could be $10s of dollars at the BSP without moving it an inch. However, that's definitely not true of all BSP markets and you need to be generally aware that your betfair orders in the future **will** change the state of the exchange, and large bets **will** move the BSP in an unfavourable direction.\n",
    "\n",
    "Aside from uncertainty around the liquidity and resiliance of the BSP, many many markets don't have a BSP. So what do we do then?\n",
    "\n",
    "Typically what a lot of people (who have a relationship with betfair australia) do at this point is request a data dump. They might request an odds file for all australian harness race win markets since june 2018 with results and 4 different price points: the BSP, the last traded price, the weighted average price (WAP) traded in 3 minutes before the race starts, and the WAP for all bets before 3 mins before the race. \n",
    "\n",
    "However, you will likely need to be an existing VIP customer to get this file and it's not ideal: it might take 2 weeks to get, you can't refresh it, you can't test more hypothetical price points after your initial analysis amongst many other problems. \n",
    "\n",
    "> What if you could produce this valuable data file yourself?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Betfair Stream Data\n",
    "\n",
    "Betfair's historical stream data is an extremely rich source of data. However, in it's raw form it's difficult to handle for the uninitiated. It also might not be immediately obvious how many different things this dataset could be used for without seeing some examples. These guides will hopefully demystify how to turn this raw data into a familiar and usable format whilst also hopefully providing some inpiration for the kinds of value that can be excavated from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Backtesting Hub Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate using the stream files to backtest the outputs to a rating system we'll use the Australian Thoroughbred Rating model available on the Betfair Hub. The most recent model iteration only goes back till Feb 28th 2021 however as an illustrative example this is fine. We'd normally want to backtest with a lot more historical data than this.\n",
    "\n",
    "I'm interested to see how we would have fared betting all selections rated by this model according to a few different staking schemes and also at a few different price points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1: Scraping The Model Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you travel to the [betfair hub ratings page](https://www.betfair.com.au/hub/horse-racing-tips/) you'll find that URL links behind the ratings download buttons have a consistent URL pattern that looks very scrape friendly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/finding-hub-ratings-url.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take advantage of this consistency and use some simple python code to scrape all the ratings into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import date, timedelta\n",
    "\n",
    "# Function to return Pandas DF of hub ratings for a particular date\n",
    "def getHubRatings(dte):\n",
    "    \n",
    "    # Substitute the date into the URL\n",
    "    url = 'https://betfair-data-supplier-prod.herokuapp.com/api/widgets/kash-ratings-model/datasets?date={}presenter=RatingsPresenter&json=true'.format(dte)\n",
    "    \n",
    "    # Convert the response into JSON\n",
    "    responseJson = requests.get(url).json()\n",
    "        \n",
    "    hubList = []\n",
    "    \n",
    "    if not responseJson:\n",
    "        return(None)\n",
    "    \n",
    "    \n",
    "    # Want an normalised table (1 row per selection)\n",
    "    # Brute force / simple approach is to loop through meetings / races / runners and pull out the key fields\n",
    "    for meeting in responseJson['meetings']:\n",
    "        for race in meeting['races']:\n",
    "            for runner in race['runners']:\n",
    "                hubList.append(\n",
    "                    {\n",
    "                        'date': dte,\n",
    "                        'track': meeting['name'],\n",
    "                        'race_number': race['number'],\n",
    "                        'race_name': race['name'],\n",
    "                        'market_id': race['bfExchangeMarketId'],\n",
    "                        'selection_id':  runner['bfExchangeSelectionId'],\n",
    "                        'selection_name': runner['name'],\n",
    "                        'model_odds': runner['ratedPrice']\n",
    "                    }\n",
    "                )\n",
    "                \n",
    "    return(pd.DataFrame(hubList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>track</th>\n",
       "      <th>race_number</th>\n",
       "      <th>race_name</th>\n",
       "      <th>market_id</th>\n",
       "      <th>selection_id</th>\n",
       "      <th>selection_name</th>\n",
       "      <th>model_odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>COWRA</td>\n",
       "      <td>1</td>\n",
       "      <td>R1 1375m Mdn</td>\n",
       "      <td>1.179845154</td>\n",
       "      <td>38620052</td>\n",
       "      <td>1. Military Affair</td>\n",
       "      <td>6.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>COWRA</td>\n",
       "      <td>1</td>\n",
       "      <td>R1 1375m Mdn</td>\n",
       "      <td>1.179845154</td>\n",
       "      <td>5889703</td>\n",
       "      <td>3. Proverbial</td>\n",
       "      <td>21.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>COWRA</td>\n",
       "      <td>1</td>\n",
       "      <td>R1 1375m Mdn</td>\n",
       "      <td>1.179845154</td>\n",
       "      <td>38177688</td>\n",
       "      <td>4. A Real Wag</td>\n",
       "      <td>9.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>COWRA</td>\n",
       "      <td>1</td>\n",
       "      <td>R1 1375m Mdn</td>\n",
       "      <td>1.179845154</td>\n",
       "      <td>38620053</td>\n",
       "      <td>5. El Jay</td>\n",
       "      <td>44.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>COWRA</td>\n",
       "      <td>1</td>\n",
       "      <td>R1 1375m Mdn</td>\n",
       "      <td>1.179845154</td>\n",
       "      <td>37263264</td>\n",
       "      <td>6. Flying Honour</td>\n",
       "      <td>3.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>YORK</td>\n",
       "      <td>7</td>\n",
       "      <td>R7 1920m Hcap</td>\n",
       "      <td>1.179845227</td>\n",
       "      <td>20465676</td>\n",
       "      <td>6. Shivers Of Joy</td>\n",
       "      <td>28.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>YORK</td>\n",
       "      <td>7</td>\n",
       "      <td>R7 1920m Hcap</td>\n",
       "      <td>1.179845227</td>\n",
       "      <td>24503237</td>\n",
       "      <td>7. Ahyoka Frost</td>\n",
       "      <td>4.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>YORK</td>\n",
       "      <td>7</td>\n",
       "      <td>R7 1920m Hcap</td>\n",
       "      <td>1.179845227</td>\n",
       "      <td>27213857</td>\n",
       "      <td>8. Doc Friar</td>\n",
       "      <td>25.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>YORK</td>\n",
       "      <td>7</td>\n",
       "      <td>R7 1920m Hcap</td>\n",
       "      <td>1.179845227</td>\n",
       "      <td>26188670</td>\n",
       "      <td>9. Praying With God</td>\n",
       "      <td>5.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>YORK</td>\n",
       "      <td>7</td>\n",
       "      <td>R7 1920m Hcap</td>\n",
       "      <td>1.179845227</td>\n",
       "      <td>10982269</td>\n",
       "      <td>10. Danish Gem</td>\n",
       "      <td>14.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  track  race_number      race_name    market_id  selection_id  \\\n",
       "0    2021-03-01  COWRA            1   R1 1375m Mdn  1.179845154      38620052   \n",
       "1    2021-03-01  COWRA            1   R1 1375m Mdn  1.179845154       5889703   \n",
       "2    2021-03-01  COWRA            1   R1 1375m Mdn  1.179845154      38177688   \n",
       "3    2021-03-01  COWRA            1   R1 1375m Mdn  1.179845154      38620053   \n",
       "4    2021-03-01  COWRA            1   R1 1375m Mdn  1.179845154      37263264   \n",
       "..          ...    ...          ...            ...          ...           ...   \n",
       "206  2021-03-01   YORK            7  R7 1920m Hcap  1.179845227      20465676   \n",
       "207  2021-03-01   YORK            7  R7 1920m Hcap  1.179845227      24503237   \n",
       "208  2021-03-01   YORK            7  R7 1920m Hcap  1.179845227      27213857   \n",
       "209  2021-03-01   YORK            7  R7 1920m Hcap  1.179845227      26188670   \n",
       "210  2021-03-01   YORK            7  R7 1920m Hcap  1.179845227      10982269   \n",
       "\n",
       "          selection_name  model_odds  \n",
       "0     1. Military Affair        6.44  \n",
       "1          3. Proverbial       21.11  \n",
       "2          4. A Real Wag        9.97  \n",
       "3              5. El Jay       44.12  \n",
       "4       6. Flying Honour        3.39  \n",
       "..                   ...         ...  \n",
       "206    6. Shivers Of Joy       28.35  \n",
       "207      7. Ahyoka Frost        4.53  \n",
       "208         8. Doc Friar       25.08  \n",
       "209  9. Praying With God        5.84  \n",
       "210       10. Danish Gem       14.12  \n",
       "\n",
       "[211 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the response from a single day\n",
    "getHubRatings(date(2021,3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-18 00:00:00\n",
      "2021-02-19 00:00:00\n",
      "2021-02-20 00:00:00\n",
      "2021-02-21 00:00:00\n",
      "2021-02-22 00:00:00\n",
      "2021-02-23 00:00:00\n",
      "2021-02-24 00:00:00\n",
      "2021-02-25 00:00:00\n",
      "2021-02-26 00:00:00\n",
      "2021-02-27 00:00:00\n",
      "2021-02-28 00:00:00\n",
      "2021-03-01 00:00:00\n",
      "2021-03-02 00:00:00\n",
      "2021-03-03 00:00:00\n",
      "2021-03-04 00:00:00\n",
      "2021-03-05 00:00:00\n",
      "2021-03-06 00:00:00\n",
      "2021-03-07 00:00:00\n",
      "2021-03-08 00:00:00\n",
      "2021-03-09 00:00:00\n",
      "2021-03-10 00:00:00\n",
      "2021-03-11 00:00:00\n",
      "2021-03-12 00:00:00\n",
      "2021-03-13 00:00:00\n",
      "2021-03-14 00:00:00\n",
      "2021-03-15 00:00:00\n",
      "2021-03-16 00:00:00\n",
      "2021-03-17 00:00:00\n",
      "2021-03-18 00:00:00\n",
      "2021-03-19 00:00:00\n",
      "2021-03-20 00:00:00\n",
      "2021-03-21 00:00:00\n",
      "2021-03-22 00:00:00\n",
      "2021-03-23 00:00:00\n",
      "2021-03-24 00:00:00\n",
      "2021-03-25 00:00:00\n",
      "2021-03-26 00:00:00\n",
      "2021-03-27 00:00:00\n",
      "2021-03-28 00:00:00\n",
      "2021-03-29 00:00:00\n",
      "2021-03-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Loop through all recent history\n",
    "dateDFList = []\n",
    "dateList = pd.date_range(date(2021,2,18),date.today()-timedelta(days=1),freq='d')\n",
    "\n",
    "for dte in dateList:\n",
    "    print(dte)\n",
    "    dateDFList.append(getHubRatings(dte))\n",
    "    \n",
    "# Concatenate (add rows to rows) all the dataframes within the list\n",
    "hubRatings = pd.concat(dateDFList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>track</th>\n",
       "      <th>race_number</th>\n",
       "      <th>race_name</th>\n",
       "      <th>market_id</th>\n",
       "      <th>selection_id</th>\n",
       "      <th>selection_name</th>\n",
       "      <th>model_odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>DOOMBEN</td>\n",
       "      <td>1</td>\n",
       "      <td>R1 1200m 3yo</td>\n",
       "      <td>1.179418181</td>\n",
       "      <td>38523320</td>\n",
       "      <td>11. Vast Kama</td>\n",
       "      <td>34.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>DOOMBEN</td>\n",
       "      <td>1</td>\n",
       "      <td>R1 1200m 3yo</td>\n",
       "      <td>1.179418181</td>\n",
       "      <td>38523319</td>\n",
       "      <td>10. Triptonic</td>\n",
       "      <td>21.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>DOOMBEN</td>\n",
       "      <td>1</td>\n",
       "      <td>R1 1200m 3yo</td>\n",
       "      <td>1.179418181</td>\n",
       "      <td>35773035</td>\n",
       "      <td>9. Right Reason</td>\n",
       "      <td>10.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>DOOMBEN</td>\n",
       "      <td>1</td>\n",
       "      <td>R1 1200m 3yo</td>\n",
       "      <td>1.179418181</td>\n",
       "      <td>38523318</td>\n",
       "      <td>8. Off Road</td>\n",
       "      <td>40.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>DOOMBEN</td>\n",
       "      <td>1</td>\n",
       "      <td>R1 1200m 3yo</td>\n",
       "      <td>1.179418181</td>\n",
       "      <td>38523317</td>\n",
       "      <td>7. More Than Value</td>\n",
       "      <td>77.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>2021-03-30</td>\n",
       "      <td>NEWCASTLE</td>\n",
       "      <td>7</td>\n",
       "      <td>R7 1400m Hcap</td>\n",
       "      <td>1.181212046</td>\n",
       "      <td>1527038</td>\n",
       "      <td>4. Excelsa</td>\n",
       "      <td>82.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>2021-03-30</td>\n",
       "      <td>NEWCASTLE</td>\n",
       "      <td>7</td>\n",
       "      <td>R7 1400m Hcap</td>\n",
       "      <td>1.181212046</td>\n",
       "      <td>35709287</td>\n",
       "      <td>3. Numbers Game</td>\n",
       "      <td>8.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>2021-03-30</td>\n",
       "      <td>NEWCASTLE</td>\n",
       "      <td>7</td>\n",
       "      <td>R7 1400m Hcap</td>\n",
       "      <td>1.181212046</td>\n",
       "      <td>35682146</td>\n",
       "      <td>2. Mensa Missile</td>\n",
       "      <td>6.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>2021-03-30</td>\n",
       "      <td>NEWCASTLE</td>\n",
       "      <td>7</td>\n",
       "      <td>R7 1400m Hcap</td>\n",
       "      <td>1.181212046</td>\n",
       "      <td>24525963</td>\n",
       "      <td>1. Controlthewitness</td>\n",
       "      <td>64.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>2021-03-30</td>\n",
       "      <td>NEWCASTLE</td>\n",
       "      <td>7</td>\n",
       "      <td>R7 1400m Hcap</td>\n",
       "      <td>1.181212046</td>\n",
       "      <td>28535873</td>\n",
       "      <td>6. Land Of Valens</td>\n",
       "      <td>18.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21817 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date      track  race_number      race_name    market_id  \\\n",
       "0   2021-02-18    DOOMBEN            1   R1 1200m 3yo  1.179418181   \n",
       "1   2021-02-18    DOOMBEN            1   R1 1200m 3yo  1.179418181   \n",
       "2   2021-02-18    DOOMBEN            1   R1 1200m 3yo  1.179418181   \n",
       "3   2021-02-18    DOOMBEN            1   R1 1200m 3yo  1.179418181   \n",
       "4   2021-02-18    DOOMBEN            1   R1 1200m 3yo  1.179418181   \n",
       "..         ...        ...          ...            ...          ...   \n",
       "310 2021-03-30  NEWCASTLE            7  R7 1400m Hcap  1.181212046   \n",
       "311 2021-03-30  NEWCASTLE            7  R7 1400m Hcap  1.181212046   \n",
       "312 2021-03-30  NEWCASTLE            7  R7 1400m Hcap  1.181212046   \n",
       "313 2021-03-30  NEWCASTLE            7  R7 1400m Hcap  1.181212046   \n",
       "314 2021-03-30  NEWCASTLE            7  R7 1400m Hcap  1.181212046   \n",
       "\n",
       "     selection_id        selection_name  model_odds  \n",
       "0        38523320         11. Vast Kama       34.28  \n",
       "1        38523319         10. Triptonic       21.22  \n",
       "2        35773035       9. Right Reason       10.23  \n",
       "3        38523318           8. Off Road       40.75  \n",
       "4        38523317    7. More Than Value       77.49  \n",
       "..            ...                   ...         ...  \n",
       "310       1527038            4. Excelsa       82.30  \n",
       "311      35709287       3. Numbers Game        8.37  \n",
       "312      35682146      2. Mensa Missile        6.33  \n",
       "313      24525963  1. Controlthewitness       64.20  \n",
       "314      28535873     6. Land Of Valens       18.43  \n",
       "\n",
       "[21817 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hubRatings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2: Assembling and Odds File\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So part 1 was very painless. This is how we like data: served by some API or available in a nice tabular format on a webpage ready to be scraped with standard tools in available in popular languages.\n",
    "\n",
    "Unfortunately, it won't be so painless to assemble our odds file. We'll find out why it's tricky as we go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we'll be using is the historical exchange data available from (this website)[https://historicdata.betfair.com/#/home]. The data available through this service is streaming JSON data. There are a few options available relating to granularity (how many time points per second the data updates at). \n",
    "\n",
    "Essentially what the data allows us to do is, for a particular market, recreate the exact state of the betfair exchange say at 150 microseconds before the market closed. What we mean when we say the **state of the exchange** we mean two things a) what are the current open orders in the exchange b) what are the current traded volumes on each selection at each price point. \n",
    "\n",
    "With these 2 pieces of information we can build a rich view of the dynamics of exchange and also build out all of the summary metrics (WAP etc) we might have previously needed betfair to help with.\n",
    "\n",
    "Now, for our purposes 50 miscro-second intervaled data is huge overkill but you could imagine needing this kind of granularity for other kinds of wagering systems - for example a high frequency trading algorithm of some sort that needed to made many decisions and actions every second. \n",
    "\n",
    "Let's take a look at what the data looks like for a single market:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/stream-data-example.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So look pretty intractable. For this particular market there's 14,384 lines which each consistent of a json packet. If you're not a data engineer (neither am I) your head might explode thinking about how you could read this into your computer and transfer it into something usable.\n",
    "\n",
    "The data looks like this because it is saved from what's called the betfair Stream API which is a special API used by the higher end of betfair API users and which that delivers fast speeds other performance improvements.\n",
    "\n",
    "Now what's good about that, for the purposes of our exercise, is the very nice python package `betfairlightweight` has the functionality build to not only parse the Stream API live but also these historical versions of the stream data. Without it we'd be *very* far away from the finish line, with it we're pretty close."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalising The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TAR Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing is these files come as tar archive files which special kind of file that we'll need to unpack. Thankfully we can do that with python too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading from tar and extracting files\n",
    "def load_markets(file_paths):\n",
    "    for file_path in file_paths:\n",
    "        print(file_path)\n",
    "        if os.path.isdir(file_path):\n",
    "            for path in glob.iglob(file_path + '**/**/*.bz2', recursive=True):\n",
    "                f = bz2.BZ2File(path, 'rb')\n",
    "                yield f\n",
    "                f.close()\n",
    "        elif os.path.isfile(file_path):\n",
    "            ext = os.path.splitext(file_path)[1]\n",
    "            # iterate through a tar archive\n",
    "            if ext == '.tar':\n",
    "                with tarfile.TarFile(file_path) as archive:\n",
    "                    for file in archive:\n",
    "                        yield bz2.open(archive.extractfile(file))\n",
    "            # or a zip archive\n",
    "            elif ext == '.zip':\n",
    "                with zipfile.ZipFile(file_path) as archive:\n",
    "                    for file in archive.namelist():\n",
    "                        yield bz2.open(archive.open(file))\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/2021_02_FebRacingPro.tar\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "must be real number, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-9b7dda078f6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[1;31m# Runner Metadata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m             runner_data = [\n\u001b[0m\u001b[0;32m    137\u001b[0m                 {\n\u001b[0;32m    138\u001b[0m                     \u001b[1;34m'selection_id'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselection_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-9b7dda078f6a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    139\u001b[0m                     \u001b[1;34m'selection_name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrd\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpostplay_market\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmarket_definition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunners\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselection_id\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselection_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m                     \u001b[1;34m'selection_status'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m                     \u001b[1;34m'sp'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactual_sp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m                 }\n\u001b[0;32m    143\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpostplay_market\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunners\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-9b7dda078f6a>\u001b[0m in \u001b[0;36mas_str\u001b[1;34m(v)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m# rounding to 2 decimal places or returning '' if blank\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;34m'%.2f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;31m# splitting race name and returning the parts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: must be real number, not str"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import betfairlightweight\n",
    "from betfairlightweight import StreamListener\n",
    "import logging\n",
    "import requests\n",
    "import tarfile\n",
    "import bz2\n",
    "from unittest.mock import patch\n",
    "\n",
    "import logging\n",
    "from typing import List, Set, Dict, Tuple, Optional\n",
    "\n",
    "from unittest.mock import patch\n",
    "from itertools import zip_longest\n",
    "import functools\n",
    "\n",
    "import os\n",
    "import tarfile\n",
    "import zipfile\n",
    "import bz2\n",
    "import glob\n",
    "\n",
    "# importing data types\n",
    "import betfairlightweight\n",
    "from betfairlightweight.resources.bettingresources import (\n",
    "    PriceSize,\n",
    "    MarketBook\n",
    ")\n",
    "\n",
    "\n",
    "data_path = [\n",
    "#     \"./data/2021_01_JanRacingPro.tar\",\n",
    "    \"./data/2021_02_FebRacingPro.tar\"\n",
    "]\n",
    "\n",
    "# Betfair Lightweight Boilerplate\n",
    "\n",
    "# create trading instance (don't need username/password)\n",
    "trading = betfairlightweight.APIClient(\"username\", \"password\")\n",
    "\n",
    "# create listener\n",
    "listener = StreamListener(max_latency=None)\n",
    "\n",
    "# rounding to 2 decimal places or returning '' if blank\n",
    "def as_str(v: float) -> str:\n",
    "    return '%.2f' % v if v is not None else ''\n",
    "\n",
    "# splitting race name and returning the parts \n",
    "def split_anz_horse_market_name(market_name: str) -> (str, str, str):\n",
    "    # return race no, length, race type\n",
    "    # input sample: R6 1400m Grp1\n",
    "    parts = market_name.split(' ')\n",
    "    race_no = parts[0] # return example R6\n",
    "    race_len = parts[1] # return example 1400m\n",
    "    race_type = parts[2].lower() # return example grp1, trot, pace\n",
    "\n",
    "    return (race_no, race_len, race_type)\n",
    "\n",
    "# filtering markets to those that fit the following criteria\n",
    "def filter_market(market: MarketBook) -> bool: \n",
    "    d = market.market_definition\n",
    "    return (d.country_code == 'AU' \n",
    "        and d.market_type == 'WIN' \n",
    "        and (c := split_anz_horse_market_name(d.name)[2]) != 'trot' and c != 'pace')\n",
    "\n",
    "# record prices to a file\n",
    "with open(\"outputs/tho-odds-feb.csv\", \"w+\") as output:\n",
    "    # defining column headers\\\n",
    "    \n",
    "    # Column Headers\n",
    "    output.write(\"market_id,event_date,country,track,market_name,selection_id,selection_name,result,bsp,matched_volume, best_back_1m, best_back_5m \\n\")\n",
    "\n",
    "    for file_obj in load_markets(data_path):\n",
    "\n",
    "        # Instantiate a \"stream\" object\n",
    "        stream = trading.streaming.create_historical_generator_stream(\n",
    "            file_path=file_obj,\n",
    "            listener=listener,\n",
    "        )\n",
    "\n",
    "\n",
    "        # For this stream object execute the following Lambda function\n",
    "        with patch(\"builtins.open\", lambda f, _: f): \n",
    "\n",
    "            evaluate_market = False\n",
    "            preplay_market = None\n",
    "            postplay_market = None\n",
    "            preplay_traded = None\n",
    "            postplay_traded = None\n",
    "            t5m = False\n",
    "            t1m = False\n",
    "\n",
    "            gen = stream.get_generator()\n",
    "            for market_books in gen():\n",
    "                for market_book in market_books:\n",
    "\n",
    "                    # skipping markets that don't meet the filter\n",
    "                    if evaluate_market == False and filter_market(market_book) == False:\n",
    "                        continue\n",
    "                    else:\n",
    "                        evaluate_market = True\n",
    "\n",
    "                    # final market view before market goes in play\n",
    "                    if preplay_market is not None and preplay_market.inplay != market_book.inplay:\n",
    "                        preplay_traded = [ (r.last_price_traded, r.ex.traded_volume.copy()) for r in preplay_market.runners ]\n",
    "                    preplay_market = market_book\n",
    "\n",
    "                    # final market view at the conclusion of the market\n",
    "                    if postplay_market is not None and postplay_market.status == \"OPEN\" and market_book.status != postplay_market.status:\n",
    "                        postplay_traded = [ (r.last_price_traded, r.ex.traded_volume.copy()) for r in market_book.runners ]\n",
    "                    postplay_market = market_book   \n",
    "                    \n",
    "                    seconds_to_start = (\n",
    "                        market_book.market_definition.market_time - market_book.publish_time\n",
    "                    ).total_seconds()\n",
    "                    \n",
    "                    # Best Available To Back 5m\n",
    "                    if not t5m:\n",
    "                        if seconds_to_start < 5*60:\n",
    "                            t5m_market = market_book\n",
    "                            t5m = True\n",
    "                            \n",
    "                    # Best Available To Back 1m\n",
    "                    if not t1m:\n",
    "                        if seconds_to_start < 1*60:\n",
    "                            t1m_market = market_book\n",
    "                            t1m = True\n",
    "                    \n",
    "            # no price data for market\n",
    "            if postplay_traded is None:\n",
    "                continue; \n",
    "\n",
    "            # Runner Metadata\n",
    "            runner_data = [\n",
    "                {\n",
    "                    'selection_id': r.selection_id,\n",
    "                    'selection_name': next((rd.name for rd in postplay_market.market_definition.runners if rd.selection_id == r.selection_id), None),\n",
    "                    'selection_status': r.status,\n",
    "                    'sp': r.sp.actual_sp\n",
    "                }\n",
    "                for r in postplay_market.runners \n",
    "            ]\n",
    "            \n",
    "            # Total Matched Volume  \n",
    "            # _____________________\n",
    "            \n",
    "            def ladder_traded_volume(ladder):\n",
    "                return(sum([rung.size for rung in ladder]))\n",
    "\n",
    "            selection_traded_volume = [ ladder_traded_volume(runner[1]) for runner in postplay_traded ]\n",
    "\n",
    "            \n",
    "            # Best Available To Back\n",
    "            # ______________________\n",
    "            \n",
    "            def best_back(availableLadder):\n",
    "                if len(availableLadder) == 0:\n",
    "                    return(None)\n",
    "                else:\n",
    "                    return(availableLadder[0].price)\n",
    "\n",
    "            bestBack5m = [ best_back(runner.ex.available_to_back) for runner in t5m_market.runners]\n",
    "\n",
    "            bestBack1m = [ best_back(runner.ex.available_to_back) for runner in t1m_market.runners]\n",
    "            \n",
    "            # Writing To CSV\n",
    "            # ______________________\n",
    "            \n",
    "            for (runnerMeta, runnerTradedVolume, bb5m, bb1m) in zip(runner_data, selection_traded_volume, bestBack5m, bestBack1m):\n",
    "                \n",
    "                output.write(\n",
    "                    \"{},{},{},{},{},{},{},{},{},{},{},{} \\n\".format(\n",
    "                        postplay_market.market_id,\n",
    "                        postplay_market.market_definition.market_time,\n",
    "                        postplay_market.market_definition.country_code,\n",
    "                        postplay_market.market_definition.venue,\n",
    "                        postplay_market.market_definition.name,\n",
    "                        runnerMeta['selection_id'],\n",
    "                        runnerMeta['selection_name'],\n",
    "                        runnerMeta['selection_status'],\n",
    "                        runnerMeta['sp'],\n",
    "                        runnerTradedVolume,\n",
    "                        bb5m,\n",
    "                        bb1m\n",
    "                    )\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
